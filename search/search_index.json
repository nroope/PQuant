{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"pruning_methods/","text":"Descriptions of the pruning methods Our implementations follow the actual implementations of the author's of the papers, whenever we were able to find one. Because of this some of the functionality of the pruning methods can differ slightly from the equations shown in the papers. Activation pruning Collect layer outputs to calculate average layer activity (how often layer neuron / channel outputs values greater than 0). Prune those neurons and channels which have smaller activity value than a given threshold. Hyperparameters - threshold : If a neuron or channel is less active than this threshold, prune it. - threshold_decay : Not used. - t_delta : How many batches to collect as calibration data. - t_start_collecting_batch : At which epoch during training the collection begins AutoSparse $x = sign(W) \\cdot ReLU(|W| - \\sigma(T))$. g = \\begin{cases} 1, & \\text{if W > 0} \\\\ \\alpha, & \\text{otherwise}\\quad, \\end{cases} where T is threshold, W is the weight matrix, g is the gradient. $\\alpha$ is decayed after each epoch using cosine sigmoid decay. Hyperparameters: - alpha : initial value for $\\alpha$ - backward_sparsity : if true, sets gradients to 0 for weights in the bottom 50% magnitude of weights in the layer. False in the default config. - threshold_decay : threshold decay for optimizer. 0 in the default config. - threshold_init : initial value for threshold. -5 in the default config. - threshold_type : weightwise/channelwise/layerwise. Defines whether each weight has its own threshold, or is threshold shared between weights in a channel, or does the whole layer have one threshold. Continuous Sparsification A multi-round pruning algorithm. x = W\\cdot M where M=(\\frac{\\sigma(\\beta s)}{\\sigma(s_{init})}) $\\beta$ starts from the initial value at the beginning of each round, and increased exponentially until reaching a final value. $s$ is a learnable matrix with a same shape as the weight matrix. $s_{init}$ is the initial value of $s$. During each round, as the $s$ matrix is learning and the $\\beta$ is increased, the values of the mask get pushed more and more towards 0 and 1. After each round, $\\beta$ is reset, and the positive values of $s$ are set to $s_{init}$ value, and negative values are kept as they are. This means that the weights pruned by $s$ stay pruned after each round, but the weights that have not been pruned previously can be pruned after a new round begins, since their values are reset in $s$. Before fine-tuning the mask is fixed and converted to a hard mask of 0s and 1s, and all the weights rewinded back to an earlier state. Hyperparameters - final_temp : Value up to which $\\beta$ is increased during each round. 200 in the default config. - threshold_decay : L1 decay for the $s$ matrix. 1.0e-09 in the default config. - threshold_init : Initial value for $s$. 0 in the default config. Lower value means more pruning, higher value means less pruning. DST $x = ReLU(|W| - T)$. g = \\begin{cases} 2-4\\cdot|W|, & \\text{if } |x| \\leq 0.4 \\\\ 0.4, & \\text{if } 0.4 < |x| \\leq 1 \\\\ 0, & \\text{if }|x| > 1\\quad. \\end{cases} The threshold T is controlled by additional loss, which is calculated by \\alpha \\cdot \\sum_{i,j}{e^{-T_{i,j}}} Hyperparameters - alpha : Used to control the threshold via loss. 5.0e-06 in the default config. - max_pruning_pct : The algorithm has a tendency to prune whole layers, so if pruning goes higher than this value, reset the threshold. 0.99 in the default config. - threshold_decay : threshold decay for optimizer. 0 in the default config. - threshold_init : Initial value for threshold. 0 in the default config. - threshold_type : weightwise/channelwise/layerwise. Defines whether each weight has its own threshold, or is threshold shared between weights in a channel, or does the whole layer have one threshold. PDP Captures weight distribution of each layer and calculates a threshold, then does a softmax between the weights and this value, creating a soft mask. $ W_h = topK(|W|, (1-r) \\cdot n(W))\\newline $\\ $ W_i = bottomK(|W|, r \\cdot n(W)) $\\ $ t = 0.5 \\cdot (min(W_h) + max(W_i)) $\\ $ zw, mw = softmax(\\frac{t^2, w^2}{\\tau})\\text{ for $w$ in $W$} $\\ $ w = mw \\cdot w $, where $\\tau$ is the temperature, $r$ is the target sparsity of the layer for that iteration, $n(W)$ is the number of weights. The $mw$ in the above equation will have all the softmax values of the weights between the weight tensor and the threshold. If a weight is above the threshold, due to the temperature, the softmax result will very quickly go towards 1. The $r$ is increased linearly during training. The layerwise budget sparsity is calculated after a pre-training phase, in a way that the total sparsity of the model is the target sparsity given in the config. PDP has an unstructured, N:M pruning (not yet implemented here), and channel pruning version. Hyperparameters epsilon : How fast to increaes the sparsity during training. After each epoch, the sparsity is increased by this amount, until the value reaches 1 (100% of target sparsity). 0.015 in the default config, which means after ~70 epochs the target sparsity has been reached. - sparsity : Target sparsity for the whole model - temperature : Temperature of the softmax. 1e-5 in the default config - threshold_decay : Not used - structured_pruning : Whether to use a structured pruning variant or not. Structured pruning uses l2 norms of the channels/neurons instead of absolute values of weights when calculating the threshold, and prunes whole channels/neurons using that threshold value. Wanda One shot pruning, originally a post-training pruning method without fine-tuning (to implement the post-training version is on the to-do list). Using a calibration data set, calculate a metric based on the average input to the layer, and multiply the absolute values of the weights with that metric. Prune weights based on this multiplication result (lowest values being pruned first), until a target sparsity has been reached. For linear layers, the metric is calculated as L2 norm over the batch dimension. For convolutions, reduce dimensions by taking the average of the batch dimension, then calculate L2 norm over a flattened kernel dimension. Hyperparameters - calculate_pruning_budget : If True, calculate the pruning budget for each layer, while keeping the target sparsity. If False, prunes every layer using target sparsity. - M : If doing N:M pruning, N and M should be non-null (N < M) - N : If doing N:M pruning, N and M should be non-null (N < M) - threshold_decay : not used - sparsity : target sparsity. 0.9 in the default config - t_delta : how many batches to collect as calibration data - t_start_collecting : training step when collection starts","title":"Descriptions of the pruning methods"},{"location":"pruning_methods/#descriptions-of-the-pruning-methods","text":"Our implementations follow the actual implementations of the author's of the papers, whenever we were able to find one. Because of this some of the functionality of the pruning methods can differ slightly from the equations shown in the papers.","title":"Descriptions of the pruning methods"},{"location":"pruning_methods/#activation-pruning","text":"Collect layer outputs to calculate average layer activity (how often layer neuron / channel outputs values greater than 0). Prune those neurons and channels which have smaller activity value than a given threshold. Hyperparameters - threshold : If a neuron or channel is less active than this threshold, prune it. - threshold_decay : Not used. - t_delta : How many batches to collect as calibration data. - t_start_collecting_batch : At which epoch during training the collection begins","title":"Activation pruning"},{"location":"pruning_methods/#autosparse","text":"$x = sign(W) \\cdot ReLU(|W| - \\sigma(T))$. g = \\begin{cases} 1, & \\text{if W > 0} \\\\ \\alpha, & \\text{otherwise}\\quad, \\end{cases} where T is threshold, W is the weight matrix, g is the gradient. $\\alpha$ is decayed after each epoch using cosine sigmoid decay. Hyperparameters: - alpha : initial value for $\\alpha$ - backward_sparsity : if true, sets gradients to 0 for weights in the bottom 50% magnitude of weights in the layer. False in the default config. - threshold_decay : threshold decay for optimizer. 0 in the default config. - threshold_init : initial value for threshold. -5 in the default config. - threshold_type : weightwise/channelwise/layerwise. Defines whether each weight has its own threshold, or is threshold shared between weights in a channel, or does the whole layer have one threshold.","title":"AutoSparse"},{"location":"pruning_methods/#continuous-sparsification","text":"A multi-round pruning algorithm. x = W\\cdot M where M=(\\frac{\\sigma(\\beta s)}{\\sigma(s_{init})}) $\\beta$ starts from the initial value at the beginning of each round, and increased exponentially until reaching a final value. $s$ is a learnable matrix with a same shape as the weight matrix. $s_{init}$ is the initial value of $s$. During each round, as the $s$ matrix is learning and the $\\beta$ is increased, the values of the mask get pushed more and more towards 0 and 1. After each round, $\\beta$ is reset, and the positive values of $s$ are set to $s_{init}$ value, and negative values are kept as they are. This means that the weights pruned by $s$ stay pruned after each round, but the weights that have not been pruned previously can be pruned after a new round begins, since their values are reset in $s$. Before fine-tuning the mask is fixed and converted to a hard mask of 0s and 1s, and all the weights rewinded back to an earlier state. Hyperparameters - final_temp : Value up to which $\\beta$ is increased during each round. 200 in the default config. - threshold_decay : L1 decay for the $s$ matrix. 1.0e-09 in the default config. - threshold_init : Initial value for $s$. 0 in the default config. Lower value means more pruning, higher value means less pruning.","title":"Continuous Sparsification"},{"location":"pruning_methods/#dst","text":"$x = ReLU(|W| - T)$. g = \\begin{cases} 2-4\\cdot|W|, & \\text{if } |x| \\leq 0.4 \\\\ 0.4, & \\text{if } 0.4 < |x| \\leq 1 \\\\ 0, & \\text{if }|x| > 1\\quad. \\end{cases} The threshold T is controlled by additional loss, which is calculated by \\alpha \\cdot \\sum_{i,j}{e^{-T_{i,j}}} Hyperparameters - alpha : Used to control the threshold via loss. 5.0e-06 in the default config. - max_pruning_pct : The algorithm has a tendency to prune whole layers, so if pruning goes higher than this value, reset the threshold. 0.99 in the default config. - threshold_decay : threshold decay for optimizer. 0 in the default config. - threshold_init : Initial value for threshold. 0 in the default config. - threshold_type : weightwise/channelwise/layerwise. Defines whether each weight has its own threshold, or is threshold shared between weights in a channel, or does the whole layer have one threshold.","title":"DST"},{"location":"pruning_methods/#pdp","text":"Captures weight distribution of each layer and calculates a threshold, then does a softmax between the weights and this value, creating a soft mask. $ W_h = topK(|W|, (1-r) \\cdot n(W))\\newline $\\ $ W_i = bottomK(|W|, r \\cdot n(W)) $\\ $ t = 0.5 \\cdot (min(W_h) + max(W_i)) $\\ $ zw, mw = softmax(\\frac{t^2, w^2}{\\tau})\\text{ for $w$ in $W$} $\\ $ w = mw \\cdot w $, where $\\tau$ is the temperature, $r$ is the target sparsity of the layer for that iteration, $n(W)$ is the number of weights. The $mw$ in the above equation will have all the softmax values of the weights between the weight tensor and the threshold. If a weight is above the threshold, due to the temperature, the softmax result will very quickly go towards 1. The $r$ is increased linearly during training. The layerwise budget sparsity is calculated after a pre-training phase, in a way that the total sparsity of the model is the target sparsity given in the config. PDP has an unstructured, N:M pruning (not yet implemented here), and channel pruning version. Hyperparameters epsilon : How fast to increaes the sparsity during training. After each epoch, the sparsity is increased by this amount, until the value reaches 1 (100% of target sparsity). 0.015 in the default config, which means after ~70 epochs the target sparsity has been reached. - sparsity : Target sparsity for the whole model - temperature : Temperature of the softmax. 1e-5 in the default config - threshold_decay : Not used - structured_pruning : Whether to use a structured pruning variant or not. Structured pruning uses l2 norms of the channels/neurons instead of absolute values of weights when calculating the threshold, and prunes whole channels/neurons using that threshold value.","title":"PDP"},{"location":"pruning_methods/#wanda","text":"One shot pruning, originally a post-training pruning method without fine-tuning (to implement the post-training version is on the to-do list). Using a calibration data set, calculate a metric based on the average input to the layer, and multiply the absolute values of the weights with that metric. Prune weights based on this multiplication result (lowest values being pruned first), until a target sparsity has been reached. For linear layers, the metric is calculated as L2 norm over the batch dimension. For convolutions, reduce dimensions by taking the average of the batch dimension, then calculate L2 norm over a flattened kernel dimension. Hyperparameters - calculate_pruning_budget : If True, calculate the pruning budget for each layer, while keeping the target sparsity. If False, prunes every layer using target sparsity. - M : If doing N:M pruning, N and M should be non-null (N < M) - N : If doing N:M pruning, N and M should be non-null (N < M) - threshold_decay : not used - sparsity : target sparsity. 0.9 in the default config - t_delta : how many batches to collect as calibration data - t_start_collecting : training step when collection starts","title":"Wanda"},{"location":"quantization_parameters/","text":"Descriptions of the quantization parameters default_integer_bits : Default integer bits used for quantization default_fractional_bits : Default fractional bits used for quantization. For ReLU, because it is unsigned and no bits are used for the sign, 1 bit is added to the default value during adding of compression layers. enable_quantization : Enables quantization hgq_gamma : scales the loss of HGQ. If too high, can prune the whole model. hgq_heterogeneous : If true, HGQ learns one set of bits for each weight in the model. If false, learns one set of bits for each layer in the model layer_specific : Layers that use non-default quantization bits, should be added here. A default config with all the layers can be created using the function pquant.add_default_layer_quantization_pruning_to_config use_high_granularity_quantization : If true, uses HGQ instead of fixed quantizers use_real_tanh : If true, use real tanh function before quantization. If false, uses hard tanh use_relu_multiplier : If true, multiply the input of QuantizedReLU with a learned multiplier before the QuantizedReLU operation. The multiplication operation will be inputs_to_relu = inputs_to_relu * 2 ** (round(learned_multiplier)) . Learned multiplier is initialized at -1, therefore at the beginning of the training the inputs are multiplied by 0.5 before QuantizedReLU. use_symmetric_quantization : if true, minimum_quantized_value == -maximum_quantized_value","title":"Descriptions of the quantization parameters"},{"location":"quantization_parameters/#descriptions-of-the-quantization-parameters","text":"default_integer_bits : Default integer bits used for quantization default_fractional_bits : Default fractional bits used for quantization. For ReLU, because it is unsigned and no bits are used for the sign, 1 bit is added to the default value during adding of compression layers. enable_quantization : Enables quantization hgq_gamma : scales the loss of HGQ. If too high, can prune the whole model. hgq_heterogeneous : If true, HGQ learns one set of bits for each weight in the model. If false, learns one set of bits for each layer in the model layer_specific : Layers that use non-default quantization bits, should be added here. A default config with all the layers can be created using the function pquant.add_default_layer_quantization_pruning_to_config use_high_granularity_quantization : If true, uses HGQ instead of fixed quantizers use_real_tanh : If true, use real tanh function before quantization. If false, uses hard tanh use_relu_multiplier : If true, multiply the input of QuantizedReLU with a learned multiplier before the QuantizedReLU operation. The multiplication operation will be inputs_to_relu = inputs_to_relu * 2 ** (round(learned_multiplier)) . Learned multiplier is initialized at -1, therefore at the beginning of the training the inputs are multiplied by 0.5 before QuantizedReLU. use_symmetric_quantization : if true, minimum_quantized_value == -maximum_quantized_value","title":"Descriptions of the quantization parameters"}]}