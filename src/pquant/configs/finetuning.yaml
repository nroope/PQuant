pruning_parameters:
    disable_pruning_for_layers:
      []
    pruning_method: pdp
quantization_parameters:
  default_integer_bits: 0.
  default_fractional_bits: 7.
  enable_quantization: true
  hgq_gamma: 0.0003
  hgq_heterogeneous: True
  layer_specific: []
  use_high_granularity_quantization: false
  use_real_tanh: false
  use_symmetric_quantization: false
training_parameters:
   batch_size: 128
   optimizer: sgd
   plot_frequency: 100
   label_smoothing: 0
   model: "resnet18"
   dataset: "cifar10"
   l2_decay:  0.001
   momentum:  0.9
   lr_schedule: "cosine"
   milestones: [30, 80]
   gamma: 0.1
   cosine_tmax: 200
   lr: 0.001
   prune_ratio: 10
   default_integer_bits: 0
   epochs: 2
   fine_tuning_epochs: 2
   pretraining_epochs: 0
   pruning_first: false
   rewind: post-ticket-search
   rounds: 2
   save_weights_epoch: 2
finetuning_parameters:
    experiment_name: resnet_18_experiment_2
    num_trials: 10
    sampler: TPESampler
    hyperparameter_search:
      numerical:
        learning_rate: [1e-5, 1e-3, 0.2]
        batch_size: [16, 128, 32]
        default_integer_bits: [0, 8, 1]
      categorical:
        lr_schedule: ["cosine", "multistep"]
